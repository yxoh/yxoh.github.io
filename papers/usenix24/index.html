<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"> <title> Quantifying Privacy Risks of Prompts in Visual Prompt Learning </title> </head> <body> <div class="paper-page"> <div class="paper-header"> <h1 class="title">Quantifying Privacy Risks of Prompts in Visual Prompt Learning</h1> <div class="authors"> <span class="author"> <span class="author-name">Yixin Wu</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Rui Wen</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Michael Backes</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Pascal Berrang</span><sup> 2 </sup> </span> , <span class="author"> <span class="author-name">Mathias Humbert</span><sup> 3 </sup> </span> , <span class="author"> <span class="author-name">Yun Shen</span><sup> 4 </sup> </span> , <span class="author"> <span class="author-name">Yang Zhang</span><sup> 1 </sup> </span> </div> <div class="affiliations"> <div class="affiliation"> <sup>1</sup>CISPA Helmholtz Center for Information Security </div> <div class="affiliation"> <sup>2</sup>University of Birmingham </div> <div class="affiliation"> <sup>3</sup>University of Lausanne </div> <div class="affiliation"> <sup>4</sup>NetApp </div> </div> <div class="conference"> <i class="fas fa-graduation-cap"></i> USENIX Security Symposium 2024 </div> </div> <div class="paper-section resources-section"> <h2> <i class="fas fa-external-link-alt"></i> Resources</h2> <div class="resource-links"> <a href="https://www.usenix.org/system/files/usenixsecurity24-wu-yixin.pdf" class="resource-btn" target="_blank" rel="external nofollow noopener"> <i class="far fa-file-pdf"></i> Paper </a> <a href="https://github.com/yxoh/prompt_leak_usenix2024/" class="resource-btn" target="_blank" rel="external nofollow noopener"> <i class="fab fa-github"></i> Code </a> <a href="https://www.usenix.org/system/files/usenixsecurity24_slides-wu-yixin.pdf" class="resource-btn" target="_blank" rel="external nofollow noopener"> <i class="fas fa-desktop"></i> Slides </a> <a href="https://www.youtube.com/watch?v=fqCQlK8LPzc&amp;t=261s" class="resource-btn" target="_blank" rel="external nofollow noopener"> <i class="fas fa-video"></i> Video </a> </div> </div> <div class="nav-container"> <div class="nav-menu"> <h3>Contents</h3> <ul> <li> <a href="#background">Background</a> </li> <li> <a href="#overview">Overview</a> </li> <li> <a href="#contributions">Contributions</a> </li> <li> <a href="#citation">Citation</a> </li> </ul> </div> </div> <div class="paper-section" id="background"> <h2> <i class="fas fa-info-circle"></i> Background</h2> <div class="section-content"> <p>Prompt learning is an emerging paradigm that enables large-scale pre-trained models to be applied to various downstream tasks. It optimizes tunable parameters, i.e., prompts, while freezing the parameters of the pre-trained models. Then, during inference, these prompts are added to query samples to make predictions.</p> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix24_background.jpeg" alt="Background" class="content-image"> <div class="content-image-caption"> Overview of visual prompt learning (VPL). We learn an input prompt via back-propagation at the input transformation stage. We apply hard-coded mapping to map the pre-trained modelâ€™s outputs into the target labels at the output transformation stage. </div> </div> </div> </div> <div class="paper-section" id="overview"> <h2> <i class="fas fa-info-circle"></i> Overview</h2> <div class="section-content"> <p>We perform the first comprehensive privacy assessment of prompts learned by visual prompt learning through the lens of property inference and membership inference attacks. Our empirical evaluation shows that the prompts are vulnerable to both attacks. We also demonstrate that the adversary can mount a successful property inference attack with limited cost. Moreover, we show that membership inference attacks against prompts can be successful with relaxed adversarial assumptions. We further make some initial investigations on the defenses and observe that our method can mitigate the membership inference attacks with a decent utility-defense trade-off but fails to defend against property inference attacks.</p> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix24.jpeg" alt="Overview" class="content-image"> <div class="content-image-caption"> Overview of prompt usage and inference attacks. The prompt is a pixel patch. The prompted image is an original image with an added prompt. Property inference infers sensitive properties of the target prompt's training dataset that the PaaS provider does not intend to disclose. Membership inference infers whether a given sample was in the target prompt's training dataset. </div> </div> </div> </div> <div class="paper-section" id="contributions"> <h2> <i class="fas fa-info-circle"></i> Contributions</h2> <div class="section-content"> <p>This work differs significantly from previous research on privacy risks. While prior studies primarily investigate the privacy risks of machine learning (ML) models, we focus on the privacy risks of prompts at the input level. Both ML models and prompts are essentially sets of parameters; however, prompts contain far fewer parameters than typical models (e.g., &lt; 0.1%). In this manner, the information in the training dataset is heavily compressed during prompt learning.</p> <p>This work presents an interesting conclusion: even though prompt learning heavily compresses training dataset information, it remains vulnerable to privacy attacks, leading to the leakage of privacy-sensitive information. Based on this conclusion, there are many potential directions for follow-up work. For example, investigating the privacy leakage of various adaptation paradigms. Given the large scale of modern pre-trained models, we often do not fine-tune the entire model. Instead, we freeze certain layers and optimize only a few. Considering our findings, we hypothesize that even when fine-tuning only a small number of parameters, models may still be vulnerable to privacy attacks. Moreover, we could explore other ML techniques related to compressed training information, such as model distillation, which might also lead to privacy leakage.</p> <p>This work also has a real-world impact, particularly in light of existing and emerging privacy regulations such as the GDPR and the EU AI Act. Our findings suggest that tunable prompts could pose unforeseen privacy risks that may need to be addressed under these regulations. As AI legislation continues to evolve, it becomes increasingly important to develop privacy-preserving techniques tailored to prompt learning and other efficient adaptation paradigms.</p> </div> </div> <div class="paper-section" id="citation"> <h2> <i class="fas fa-quote-right"></i> Citation</h2> <div class="citation"> <pre><code>@inproceedings{WWBBHSZ24,
  title={Quantifying Privacy Risks of Prompts in Visual Prompt Learning},
  author={Wu, Yixin and Wen, Rui and Backes, Michael and Berrang, Pascal and Humbert, Mathias and Shen, Yun and Zhang, Yang},
  booktitle={USENIX Security Symposium},
  year={2024}
}
</code></pre> <button class="copy-btn" onclick="copyToClipboard(this)"> <i class="far fa-copy"></i> Copy </button> </div> </div> </div> <style>.paper-page{max-width:900px;margin:0 auto;padding:2rem;background:linear-gradient(to bottom,#fff,#f8f9fa);min-height:100vh}.paper-header{text-align:center;margin-bottom:3rem;padding-bottom:2rem;border-bottom:2px solid #eee}.paper-header .title{color:var(--global-theme-color);margin-bottom:1.5rem;font-size:2.2rem;font-weight:bold;line-height:1.4}.paper-header .authors{font-size:1.2rem;color:var(--global-text-color);margin:1.5rem 0;display:flex;flex-wrap:wrap;justify-content:center;gap:.3rem .7rem}.paper-header .author{display:inline-flex;align-items:baseline;white-space:nowrap}.paper-header .author-name{font-weight:500}.paper-header .author sup{position:relative;top:-0.5em;font-size:.7em;color:var(--global-theme-color);font-weight:bold;margin-left:1px}.paper-header .affiliations{color:var(--global-text-color-light);margin:.5rem 0 1.5rem 0;text-align:center}.paper-header .affiliation{margin:.3rem 0;display:flex;justify-content:center;gap:.3rem}.paper-header .affiliation sup{color:var(--global-theme-color);font-weight:bold;margin-right:.3rem}.paper-header sup{color:var(--global-theme-color);font-weight:bold;font-size:.75em}.paper-header .conference{color:var(--global-theme-color);font-style:italic;font-size:1.1rem}.resources-section{text-align:center}.resource-links{display:flex;justify-content:center;gap:1rem;flex-wrap:wrap;padding:.5rem}.resource-btn{padding:.8rem 1.5rem;border:2px solid var(--global-theme-color);border-radius:10px;color:var(--global-theme-color);text-decoration:none;font-weight:bold;transition:all .3s ease;display:inline-flex;align-items:center;gap:.5rem;background:transparent}.resource-btn:hover{background:var(--global-theme-color);color:white;transform:translateY(-2px);text-decoration:none}.resource-btn i{font-size:1.2rem}.venue-icon{width:16px;height:16px;object-fit:contain;vertical-align:middle}.paper-section{margin:3rem 0;background:white;padding:2rem;border-radius:10px;box-shadow:0 2px 15px rgba(0,0,0,0.05)}.paper-section h2{color:var(--global-theme-color);margin-bottom:1.5rem;font-size:1.5rem;display:flex;align-items:center;gap:.5rem;padding-bottom:.5rem;border-bottom:2px solid rgba(var(--global-theme-color-rgb),0.1)}.paper-section h2 i{color:var(--global-theme-color);font-size:1.3rem;opacity:.9;background:rgba(var(--global-theme-color-rgb),0.1);width:35px;height:35px;display:flex;align-items:center;justify-content:center;border-radius:8px}.section-content{font-size:1.1rem;line-height:1.6;color:var(--global-text-color)}.citation{background:#f8f9fa;padding:1.5rem;border-radius:8px;position:relative}.citation pre{margin:0;white-space:pre-wrap;font-size:.9rem}.copy-btn{position:absolute;top:1rem;right:1rem;padding:.5rem 1rem;background:white;border:1px solid #ddd;border-radius:4px;cursor:pointer;transition:all .3s ease;display:flex;align-items:center;gap:.3rem}.copy-btn:hover{background:#f0f0f0}@media(max-width:768px){.paper-page{padding:1rem}.paper-header .title{font-size:1.8rem}.resource-btn{padding:.6rem 1rem;font-size:.9rem}.resource-btn i{font-size:1rem}.venue-icon{width:14px;height:14px}.paper-section{padding:1.5rem}.paper-section h2{font-size:1.3rem}.paper-section h2 i{width:30px;height:30px;font-size:1.1rem}}.pdf-fallback{padding:2rem;background:#f8f9fa;border-radius:8px;color:var(--global-text-color)}.equal-contribution{font-size:.9rem;color:var(--global-text-color-light);margin-top:.5rem;font-style:italic}.disclaimer-section{margin-top:2rem;border-left:3px solid #dc3545;background:rgba(220,53,69,0.05);padding:.7rem 1.5rem}.disclaimer-section h2{color:#dc3545!important;display:flex;align-items:center;gap:.5rem;font-size:1.1rem;margin:0 0 .5rem 0;padding-bottom:.3rem;border-bottom:1px solid rgba(220,53,69,0.1)}.disclaimer-content{font-size:.9rem;color:#dc3545;line-height:1.4}.disclaimer-content p{margin:0}.disclaimer-content p:last-child{margin-bottom:0}.content-image-container{text-align:center;margin:.1rem 0}.content-image{max-width:100%;height:auto;border-radius:8px;margin:.1rem 0}.content-image-caption{margin-top:.1rem;color:var(--global-text-color-light);font-style:italic;font-size:.95rem;text-align:left;padding:0;line-height:1.5}.nav-container{position:fixed;left:20px;top:100px;width:200px;z-index:1000}.nav-menu{background-color:var(--global-bg-color);border:1px solid var(--global-divider-color);border-radius:8px;padding:15px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.nav-menu h3{margin:0 0 10px 0;font-size:1.1rem;color:var(--global-text-color)}.nav-menu ul{list-style:none;padding:0;margin:0}.nav-menu li{margin:8px 0}.nav-menu a{color:var(--global-text-color-light);text-decoration:none;font-size:.9rem;transition:color .3s ease}.nav-menu a:hover{color:var(--global-theme-color)}@media(max-width:1200px){.nav-container{display:none}}</style> <script>function copyToClipboard(e){const n=e.parentElement.querySelector("pre").textContent;navigator.clipboard.writeText(n).then(()=>{const n=e.innerHTML;e.innerHTML='<i class="fas fa-check"></i> Copied!',setTimeout(()=>{e.innerHTML=n},2e3)})}</script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["\\(","\\)"]],displayMath:[["\\[","\\]"]],processEscapes:!0},svg:{fontCache:"global"}};</script> <script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script> </body> </html>