<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css"> <title> Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications </title> </head> <body> <div class="paper-page"> <div class="paper-header"> <h1 class="title">Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications</h1> <div class="authors"> <span class="author"> <span class="author-name">Yixin Wu</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Ziqing Yang</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Yun Shen</span><sup> 2 </sup> </span> , <span class="author"> <span class="author-name">Michael Backes</span><sup> 1 </sup> </span> , <span class="author"> <span class="author-name">Yang Zhang</span><sup> 1 </sup> </span> </div> <div class="affiliations"> <div class="affiliation"> <sup>1</sup>CISPA Helmholtz Center for Information Security </div> <div class="affiliation"> <sup>2</sup>NetApp </div> </div> <div class="conference"> <i class="fas fa-graduation-cap"></i> USENIX Security Symposium 2025 </div> </div> <div class="paper-section resources-section"> <h2> <i class="fas fa-external-link-alt"></i> Resources</h2> <div class="resource-links"> <a href="." class="resource-btn" target="_blank"> <i class="far fa-file-pdf"></i> Paper </a> <a href="https://github.com/TrustAIRLab/synthetic_artifact_auditing" class="resource-btn" target="_blank" rel="external nofollow noopener"> <i class="fab fa-github"></i> Code </a> <a href="." class="resource-btn" target="_blank"> <i class="fas fa-desktop"></i> Slides </a> <a href="." class="resource-btn" target="_blank"> <i class="fas fa-video"></i> Video </a> </div> </div> <div class="nav-container"> <div class="nav-menu"> <h3>Contents</h3> <ul> <li> <a href="#novel-concept">Novel Concept</a> </li> <li> <a href="#motivation">Motivation</a> </li> <li> <a href="#main-contributions">Main Contributions</a> </li> <li> <a href="#real-data-vs-synthetic-data-zero-shot">Real Data vs. Synthetic Data (Zero-Shot)</a> </li> <li> <a href="#real-data-vs-synthetic-data-paraphrasing">Real Data vs. Synthetic Data (Paraphrasing)</a> </li> <li> <a href="#hypothesis">Hypothesis</a> </li> <li> <a href="#auditing-methods">Auditing Methods</a> </li> <li> <a href="#evaluation">Evaluation</a> </li> <li> <a href="#impact">Impact</a> </li> <li> <a href="#citation">Citation</a> </li> </ul> </div> </div> <div class="paper-section" id="novel-concept"> <h2> <i class="fas fa-info-circle"></i> Novel Concept</h2> <div class="section-content"> <p>We introduce the concept of synthetic artifact auditing. Given a target artifact, we aim to determine whether the synthetic data was involved in the developing process.</p> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix25a_concept.jpeg" alt="Novel Concept" class="content-image"> </div> </div> </div> <div class="paper-section" id="motivation"> <h2> <i class="fas fa-info-circle"></i> Motivation</h2> <div class="section-content"> <p>Synthetic data have the potential to contain biases and hallucination. In downstream training and analysis process, the bias and inaccurate information could undermine the reliability of the decision-making process.</p> <p>Thinking of a real life example of treating potential risks to the consumers with allergies, the allergen labeling is a practice to identifies and discloses the presence of potential allergens in food products to protect consumers with allergies.</p> <p>In the same vein, to raise users’ awareness and thereby reduce unexpected consequences and risks in downstream applications, it is necessary to label those trained on or derived from synthetic data!</p> <p>Furthermore, many AI companies have usage terms that prohibit competitors from using synthetic data to develop competing products. Nowadays, there are news reports about unauthorized use behaviors that violate such usage terms. There is an emergent need for an auditing tool that assists them in collecting evidence of these unauthorized uses.</p> </div> </div> <div class="paper-section" id="main-contributions"> <h2> <i class="fas fa-info-circle"></i> Main Contributions</h2> <div class="section-content"> <ul> <li> <p><strong>Novel Concept</strong>: We introduce the concept of synthetic artifact auditing. Given an artifact, it determines whether it is trained on or derived from LLM-generated synthetic data.</p> </li> <li> <p><strong>Novel Techniques</strong>: We propose an auditing framework with three methods that require no disclosure of proprietary training specifics: metric-based auditing, tuning-based auditing, and classification-based auditing. This framework is extendable, currently supporting auditing for classifiers, generators, and statistical plots.</p> </li> <li> <p><strong>Extensive Evaluation</strong>: We evaluate our auditing framework on seven downstream tasks across three training scenarios. The evaluation demonstrates the effectiveness of all proposed auditing methods across all these tasks.</p> </li> </ul> </div> </div> <div class="paper-section" id="real-data-vs-synthetic-data-zero-shot"> <h2> <i class="fas fa-info-circle"></i> Real Data vs. Synthetic Data (Zero-Shot)</h2> <div class="section-content"> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix25a_intuition2.jpeg" alt="Real Data vs. Synthetic Data (Zero-Shot)" class="content-image"> <div class="content-image-caption"> The distribution for 2-class real data appears well mixed. We generate synthetic data conditioned on the label (positive or negative). Two distinct small groups of yellow and purple points at the bottom, indicates different structural pattern in the data. With the synthetic proportion increases, the distinction between data samples from different classes becomes more pronounced, leading to a more distinct decision boundary. </div> </div> </div> </div> <div class="paper-section" id="real-data-vs-synthetic-data-paraphrasing"> <h2> <i class="fas fa-info-circle"></i> Real Data vs. Synthetic Data (Paraphrasing)</h2> <div class="section-content"> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix25a_intuition1.jpeg" alt="Real Data vs. Synthetic Data (Paraphrasing)" class="content-image"> <div class="content-image-caption"> We then generate synthetic data by paraphrasing existing real data and we can still see a clearer decision boundary between data from different classes, which distinguish the real and synthetic data. </div> </div> </div> </div> <div class="paper-section" id="hypothesis"> <h2> <i class="fas fa-info-circle"></i> Hypothesis</h2> <div class="section-content"> <ul> <li>Synthetic classifiers tend to be more confident when predicting labels for synthetic input texts and less confident with real input texts compared to real classifiers.</li> <li>Real classifiers tend to be more confident when predicting labels for real input texts and less confident with synthetic input texts compared to synthetic classifiers.</li> </ul> </div> </div> <div class="paper-section" id="auditing-methods"> <h2> <i class="fas fa-info-circle"></i> Auditing Methods</h2> <div class="section-content"> <p>In general, our auditing framework follows a procedure:</p> <ol> <li>We train a set of reference synthetic and real artifacts.</li> <li>By feeding a set of queries into reference artifacts, we get the corresponding outputs, measure them with the performance metrics, and get the threshold.</li> <li>Then, at the inference time, we feed the same queries into target artifact to calculate the metric value and compare it with the threshold to determine whether the synthetic data was involved.</li> </ol> <p>Queries:</p> <ul> <li>With black-box access, we consider random synthetic input texts or real input texts.</li> <li>With white-box access, we tune queries—essentially embeddings—that best represent the unique pattern distinguishing synthetic artifacts from real artifacts.</li> <li>The statistical plots do not provide output to measure performance, but we can directly see the difference between the synthetic and real data, as shown in the t-SNE plots. Therefore, we consider using an image classifier to determine whether synthetic data is involved.</li> </ul> <div class="content-image-container"> <img src="/assets/img/publication_preview/usenix25a_auditing.jpeg" alt="Auditing Methods" class="content-image"> <div class="content-image-caption"> The general auditing framework. </div> </div> </div> </div> <div class="paper-section" id="evaluation"> <h2> <i class="fas fa-info-circle"></i> Evaluation</h2> <div class="section-content"> <ul> <li> <p>This paper evaluates the auditing framework on three text classification tasks, two text summarization tasks, and two data visualization tasks with four LLMs across three scenarios.</p> </li> <li>The three scenarios for training synthetic artifacts are: <ol> <li>\(S_1\): Training exclusively on synthetic data (100%) generated from a single LLM.</li> <li>\(S_2\): Training on a mix of real and synthetic data from a single LLM; In evaluation, we vary the proportion of synthetic data from 10% to 100% in increments of 10%.</li> <li>\(S_3\): Training on a mix of real and synthetic data from multiple LLMs (all four LLMs); The proportions of synthetic data are randomized.</li> </ol> </li> <li>In general, it can achieve good auditing performance across all tasks and scenarios. With black-box access and limited resources, it achieves an average accuracy of 0.868±0.071 for auditing classifiers and 0.880±0.052 for auditing generators. Meanwhile, it can also achieve 0.966±0.003 average accuracy for auditing statistical plots.</li> </ul> </div> </div> <div class="paper-section" id="impact"> <h2> <i class="fas fa-info-circle"></i> Impact</h2> <div class="section-content"> <p>Our work has a real-world impact in promoting the responsible use of synthetic data and aligning with corresponding regulations and laws. Regulatory and governmental bodies are increasingly prioritizing data governance and transparency in the development of AI systems. For instance, the UK’s ICO requires documentation of synthetic data creation and its properties. Similarly, California recently passed Law AB 2013, mandating the disclosure of training datasets, including the use of synthetic data. Our framework provides a practical means for third parties to audit artifacts without requiring the disclosure of proprietary training details by artifact owners. This supports compliance with data governance and transparency requirements, enhances alignment with regulatory and legal standards (e.g., EU AI Act), and facilitates responsible and accountable AI practices.</p> </div> </div> <div class="paper-section" id="citation"> <h2> <i class="fas fa-quote-right"></i> Citation</h2> <div class="citation"> <pre><code>@inproceedings{WYSBZ25,
  title={Synthetic Artifact Auditing: Tracing LLM-Generated Synthetic Data Usage in Downstream Applications},
  author={Wu, Yixin and Yang, Ziqing and Shen, Yun and Backes, Michael and Zhang, Yang},
  booktitle={USENIX Security Symposium},
  year={2025}
}
</code></pre> <button class="copy-btn" onclick="copyToClipboard(this)"> <i class="far fa-copy"></i> Copy </button> </div> </div> </div> <style>.paper-page{max-width:900px;margin:0 auto;padding:2rem;background:linear-gradient(to bottom,#fff,#f8f9fa);min-height:100vh}.paper-header{text-align:center;margin-bottom:3rem;padding-bottom:2rem;border-bottom:2px solid #eee}.paper-header .title{color:var(--global-theme-color);margin-bottom:1.5rem;font-size:2.2rem;font-weight:bold;line-height:1.4}.paper-header .authors{font-size:1.2rem;color:var(--global-text-color);margin:1.5rem 0;display:flex;flex-wrap:wrap;justify-content:center;gap:.3rem .7rem}.paper-header .author{display:inline-flex;align-items:baseline;white-space:nowrap}.paper-header .author-name{font-weight:500}.paper-header .author sup{position:relative;top:-0.5em;font-size:.7em;color:var(--global-theme-color);font-weight:bold;margin-left:1px}.paper-header .affiliations{color:var(--global-text-color-light);margin:.5rem 0 1.5rem 0;text-align:center}.paper-header .affiliation{margin:.3rem 0;display:flex;justify-content:center;gap:.3rem}.paper-header .affiliation sup{color:var(--global-theme-color);font-weight:bold;margin-right:.3rem}.paper-header sup{color:var(--global-theme-color);font-weight:bold;font-size:.75em}.paper-header .conference{color:var(--global-theme-color);font-style:italic;font-size:1.1rem}.resources-section{text-align:center}.resource-links{display:flex;justify-content:center;gap:1rem;flex-wrap:wrap;padding:.5rem}.resource-btn{padding:.8rem 1.5rem;border:2px solid var(--global-theme-color);border-radius:10px;color:var(--global-theme-color);text-decoration:none;font-weight:bold;transition:all .3s ease;display:inline-flex;align-items:center;gap:.5rem;background:transparent}.resource-btn:hover{background:var(--global-theme-color);color:white;transform:translateY(-2px);text-decoration:none}.resource-btn i{font-size:1.2rem}.venue-icon{width:16px;height:16px;object-fit:contain;vertical-align:middle}.paper-section{margin:3rem 0;background:white;padding:2rem;border-radius:10px;box-shadow:0 2px 15px rgba(0,0,0,0.05)}.paper-section h2{color:var(--global-theme-color);margin-bottom:1.5rem;font-size:1.5rem;display:flex;align-items:center;gap:.5rem;padding-bottom:.5rem;border-bottom:2px solid rgba(var(--global-theme-color-rgb),0.1)}.paper-section h2 i{color:var(--global-theme-color);font-size:1.3rem;opacity:.9;background:rgba(var(--global-theme-color-rgb),0.1);width:35px;height:35px;display:flex;align-items:center;justify-content:center;border-radius:8px}.section-content{font-size:1.1rem;line-height:1.6;color:var(--global-text-color)}.citation{background:#f8f9fa;padding:1.5rem;border-radius:8px;position:relative}.citation pre{margin:0;white-space:pre-wrap;font-size:.9rem}.copy-btn{position:absolute;top:1rem;right:1rem;padding:.5rem 1rem;background:white;border:1px solid #ddd;border-radius:4px;cursor:pointer;transition:all .3s ease;display:flex;align-items:center;gap:.3rem}.copy-btn:hover{background:#f0f0f0}@media(max-width:768px){.paper-page{padding:1rem}.paper-header .title{font-size:1.8rem}.resource-btn{padding:.6rem 1rem;font-size:.9rem}.resource-btn i{font-size:1rem}.venue-icon{width:14px;height:14px}.paper-section{padding:1.5rem}.paper-section h2{font-size:1.3rem}.paper-section h2 i{width:30px;height:30px;font-size:1.1rem}}.pdf-fallback{padding:2rem;background:#f8f9fa;border-radius:8px;color:var(--global-text-color)}.equal-contribution{font-size:.9rem;color:var(--global-text-color-light);margin-top:.5rem;font-style:italic}.disclaimer-section{margin-top:2rem;border-left:3px solid #dc3545;background:rgba(220,53,69,0.05);padding:.7rem 1.5rem}.disclaimer-section h2{color:#dc3545!important;display:flex;align-items:center;gap:.5rem;font-size:1.1rem;margin:0 0 .5rem 0;padding-bottom:.3rem;border-bottom:1px solid rgba(220,53,69,0.1)}.disclaimer-content{font-size:.9rem;color:#dc3545;line-height:1.4}.disclaimer-content p{margin:0}.disclaimer-content p:last-child{margin-bottom:0}.content-image-container{text-align:center;margin:.1rem 0}.content-image{max-width:100%;height:auto;border-radius:8px;margin:.1rem 0}.content-image-caption{margin-top:.1rem;color:var(--global-text-color-light);font-style:italic;font-size:.95rem;text-align:left;padding:0;line-height:1.5}.nav-container{position:fixed;left:20px;top:100px;width:200px;z-index:1000}.nav-menu{background-color:var(--global-bg-color);border:1px solid var(--global-divider-color);border-radius:8px;padding:15px;box-shadow:0 2px 4px rgba(0,0,0,0.1)}.nav-menu h3{margin:0 0 10px 0;font-size:1.1rem;color:var(--global-text-color)}.nav-menu ul{list-style:none;padding:0;margin:0}.nav-menu li{margin:8px 0}.nav-menu a{color:var(--global-text-color-light);text-decoration:none;font-size:.9rem;transition:color .3s ease}.nav-menu a:hover{color:var(--global-theme-color)}@media(max-width:1200px){.nav-container{display:none}}</style> <script>function copyToClipboard(e){const n=e.parentElement.querySelector("pre").textContent;navigator.clipboard.writeText(n).then(()=>{const n=e.innerHTML;e.innerHTML='<i class="fas fa-check"></i> Copied!',setTimeout(()=>{e.innerHTML=n},2e3)})}</script> <script type="text/javascript">window.MathJax={tex:{inlineMath:[["\\(","\\)"]],displayMath:[["\\[","\\]"]],processEscapes:!0},svg:{fontCache:"global"}};</script> <script type="text/javascript" id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js"> </script> </body> </html>